{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('climate-model-simulation-crashes_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check our the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>0.252866</td>\n",
       "      <td>0.298838</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.735936</td>\n",
       "      <td>0.428325</td>\n",
       "      <td>0.567947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245675</td>\n",
       "      <td>0.104226</td>\n",
       "      <td>0.869091</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>0.448620</td>\n",
       "      <td>0.307522</td>\n",
       "      <td>0.858310</td>\n",
       "      <td>0.796997</td>\n",
       "      <td>0.869893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>0.457728</td>\n",
       "      <td>0.359448</td>\n",
       "      <td>0.306957</td>\n",
       "      <td>0.843331</td>\n",
       "      <td>0.934851</td>\n",
       "      <td>0.444572</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616870</td>\n",
       "      <td>0.975786</td>\n",
       "      <td>0.914344</td>\n",
       "      <td>0.845247</td>\n",
       "      <td>0.864152</td>\n",
       "      <td>0.346713</td>\n",
       "      <td>0.356573</td>\n",
       "      <td>0.438447</td>\n",
       "      <td>0.512256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>202</td>\n",
       "      <td>0.373238</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>0.504993</td>\n",
       "      <td>0.618903</td>\n",
       "      <td>0.605571</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.195928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>0.803413</td>\n",
       "      <td>0.643995</td>\n",
       "      <td>0.718441</td>\n",
       "      <td>0.924775</td>\n",
       "      <td>0.315371</td>\n",
       "      <td>0.250642</td>\n",
       "      <td>0.285636</td>\n",
       "      <td>0.365858</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>0.104055</td>\n",
       "      <td>0.197533</td>\n",
       "      <td>0.421837</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.490828</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.392123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471463</td>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.761659</td>\n",
       "      <td>0.362751</td>\n",
       "      <td>0.912819</td>\n",
       "      <td>0.977971</td>\n",
       "      <td>0.845921</td>\n",
       "      <td>0.699431</td>\n",
       "      <td>0.475987</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>278</td>\n",
       "      <td>0.513199</td>\n",
       "      <td>0.061812</td>\n",
       "      <td>0.635837</td>\n",
       "      <td>0.844798</td>\n",
       "      <td>0.441502</td>\n",
       "      <td>0.191926</td>\n",
       "      <td>0.487546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551543</td>\n",
       "      <td>0.743877</td>\n",
       "      <td>0.312349</td>\n",
       "      <td>0.650223</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.043545</td>\n",
       "      <td>0.376660</td>\n",
       "      <td>0.280098</td>\n",
       "      <td>0.132283</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2   V3        V4        V5        V6        V7        V8        V9  \\\n",
       "0   1   1  502  0.927825  0.252866  0.298838  0.170521  0.735936  0.428325   \n",
       "1   1   2  249  0.457728  0.359448  0.306957  0.843331  0.934851  0.444572   \n",
       "2   1   3  202  0.373238  0.517399  0.504993  0.618903  0.605571  0.746225   \n",
       "3   1   4   56  0.104055  0.197533  0.421837  0.742056  0.490828  0.005525   \n",
       "4   1   5  278  0.513199  0.061812  0.635837  0.844798  0.441502  0.191926   \n",
       "\n",
       "        V10  ...         V12       V13       V14       V15       V16  \\\n",
       "0  0.567947  ...    0.245675  0.104226  0.869091  0.997518  0.448620   \n",
       "1  0.828015  ...    0.616870  0.975786  0.914344  0.845247  0.864152   \n",
       "2  0.195928  ...    0.679355  0.803413  0.643995  0.718441  0.924775   \n",
       "3  0.392123  ...    0.471463  0.597879  0.761659  0.362751  0.912819   \n",
       "4  0.487546  ...    0.551543  0.743877  0.312349  0.650223  0.522261   \n",
       "\n",
       "        V17       V18       V19       V20  Class  \n",
       "0  0.307522  0.858310  0.796997  0.869893      1  \n",
       "1  0.346713  0.356573  0.438447  0.512256      2  \n",
       "2  0.315371  0.250642  0.285636  0.365858      2  \n",
       "3  0.977971  0.845921  0.699431  0.475987      2  \n",
       "4  0.043545  0.376660  0.280098  0.132283      2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line gives the transposed summary statistics of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>540</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.817254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>540</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>52.008901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.750000</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>135.250000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>540</td>\n",
       "      <td>270.500000</td>\n",
       "      <td>156.028843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.750000</td>\n",
       "      <td>270.500000</td>\n",
       "      <td>405.250000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500096</td>\n",
       "      <td>0.288922</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.251597</td>\n",
       "      <td>0.499596</td>\n",
       "      <td>0.750011</td>\n",
       "      <td>0.998815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.289067</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.251540</td>\n",
       "      <td>0.500104</td>\n",
       "      <td>0.749180</td>\n",
       "      <td>0.998263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500119</td>\n",
       "      <td>0.288993</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.250159</td>\n",
       "      <td>0.500456</td>\n",
       "      <td>0.750348</td>\n",
       "      <td>0.997673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.288827</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.250630</td>\n",
       "      <td>0.500903</td>\n",
       "      <td>0.748988</td>\n",
       "      <td>0.998944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>540</td>\n",
       "      <td>0.499913</td>\n",
       "      <td>0.288852</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.251325</td>\n",
       "      <td>0.499174</td>\n",
       "      <td>0.748166</td>\n",
       "      <td>0.997142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500059</td>\n",
       "      <td>0.289010</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.253047</td>\n",
       "      <td>0.499070</td>\n",
       "      <td>0.750109</td>\n",
       "      <td>0.998930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500076</td>\n",
       "      <td>0.288909</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.250402</td>\n",
       "      <td>0.500074</td>\n",
       "      <td>0.749091</td>\n",
       "      <td>0.998506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500044</td>\n",
       "      <td>0.288860</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.252661</td>\n",
       "      <td>0.500295</td>\n",
       "      <td>0.748606</td>\n",
       "      <td>0.997172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>0.288966</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.250758</td>\n",
       "      <td>0.500393</td>\n",
       "      <td>0.749447</td>\n",
       "      <td>0.999536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>540</td>\n",
       "      <td>0.499984</td>\n",
       "      <td>0.289127</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.251677</td>\n",
       "      <td>0.500322</td>\n",
       "      <td>0.749346</td>\n",
       "      <td>0.999942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500032</td>\n",
       "      <td>0.289013</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.249669</td>\n",
       "      <td>0.500150</td>\n",
       "      <td>0.749164</td>\n",
       "      <td>0.997718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>540</td>\n",
       "      <td>0.499933</td>\n",
       "      <td>0.288822</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.249988</td>\n",
       "      <td>0.500625</td>\n",
       "      <td>0.749569</td>\n",
       "      <td>0.997518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>540</td>\n",
       "      <td>0.499944</td>\n",
       "      <td>0.288949</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.249586</td>\n",
       "      <td>0.499080</td>\n",
       "      <td>0.750012</td>\n",
       "      <td>0.999795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>540</td>\n",
       "      <td>0.499945</td>\n",
       "      <td>0.288923</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.249974</td>\n",
       "      <td>0.499959</td>\n",
       "      <td>0.747978</td>\n",
       "      <td>0.999155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500044</td>\n",
       "      <td>0.288813</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.250412</td>\n",
       "      <td>0.500385</td>\n",
       "      <td>0.749256</td>\n",
       "      <td>0.997265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500020</td>\n",
       "      <td>0.288936</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.252739</td>\n",
       "      <td>0.498954</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.999306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>540</td>\n",
       "      <td>0.500021</td>\n",
       "      <td>0.289013</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.249723</td>\n",
       "      <td>0.499431</td>\n",
       "      <td>0.749792</td>\n",
       "      <td>0.999655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>540</td>\n",
       "      <td>1.914815</td>\n",
       "      <td>0.279416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count        mean         std       min         25%         50%  \\\n",
       "V1       540    2.000000    0.817254  1.000000    1.000000    2.000000   \n",
       "V2       540   90.500000   52.008901  1.000000   45.750000   90.500000   \n",
       "V3       540  270.500000  156.028843  1.000000  135.750000  270.500000   \n",
       "V4       540    0.500096    0.288922  0.001922    0.251597    0.499596   \n",
       "V5       540    0.500027    0.289067  0.001181    0.251540    0.500104   \n",
       "V6       540    0.500119    0.288993  0.001972    0.250159    0.500456   \n",
       "V7       540    0.500001    0.288827  0.000858    0.250630    0.500903   \n",
       "V8       540    0.499913    0.288852  0.000476    0.251325    0.499174   \n",
       "V9       540    0.500059    0.289010  0.004590    0.253047    0.499070   \n",
       "V10      540    0.500076    0.288909  0.000296    0.250402    0.500074   \n",
       "V11      540    0.500044    0.288860  0.003231    0.252661    0.500295   \n",
       "V12      540    0.500111    0.288966  0.002015    0.250758    0.500393   \n",
       "V13      540    0.499984    0.289127  0.000419    0.251677    0.500322   \n",
       "V14      540    0.500032    0.289013  0.001188    0.249669    0.500150   \n",
       "V15      540    0.499933    0.288822  0.001312    0.249988    0.500625   \n",
       "V16      540    0.499944    0.288949  0.002509    0.249586    0.499080   \n",
       "V17      540    0.499945    0.288923  0.000732    0.249974    0.499959   \n",
       "V18      540    0.500044    0.288813  0.000891    0.250412    0.500385   \n",
       "V19      540    0.500020    0.288936  0.000219    0.252739    0.498954   \n",
       "V20      540    0.500021    0.289013  0.000263    0.249723    0.499431   \n",
       "Class    540    1.914815    0.279416  1.000000    2.000000    2.000000   \n",
       "\n",
       "              75%         max  \n",
       "V1       3.000000    3.000000  \n",
       "V2     135.250000  180.000000  \n",
       "V3     405.250000  540.000000  \n",
       "V4       0.750011    0.998815  \n",
       "V5       0.749180    0.998263  \n",
       "V6       0.750348    0.997673  \n",
       "V7       0.748988    0.998944  \n",
       "V8       0.748166    0.997142  \n",
       "V9       0.750109    0.998930  \n",
       "V10      0.749091    0.998506  \n",
       "V11      0.748606    0.997172  \n",
       "V12      0.749447    0.999536  \n",
       "V13      0.749346    0.999942  \n",
       "V14      0.749164    0.997718  \n",
       "V15      0.749569    0.997518  \n",
       "V16      0.750012    0.999795  \n",
       "V17      0.747978    0.999155  \n",
       "V18      0.749256    0.997265  \n",
       "V19      0.748538    0.999306  \n",
       "V20      0.749792    0.999655  \n",
       "Class    2.000000    2.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prints the shape-540 observations of a 21 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 21)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up our data and our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data into training and testing sets, this is done easily with scikit learn's train_test_split function \n",
    "from model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the built-in StandardScaler for standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building, Predicting and Evaluating the neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with hidden_layer_sizesargument set to three layers, has the same number of neurons as the count \n",
    "features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes = (11, 11, 11), max_iter = 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(11, 11, 11), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=750, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model it is time to use it to get predictions. We can do this simply with the predict() method off of our fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Scikit-learn built in metrics such a classification report and confusion matrix to evaluate how well our model performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5   5]\n",
      " [  4 121]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.50      0.53        10\n",
      "           2       0.96      0.97      0.96       125\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       135\n",
      "   macro avg       0.76      0.73      0.75       135\n",
      "weighted avg       0.93      0.93      0.93       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows the performance of the model in test data. The accuray f1 score is about 0.89, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
